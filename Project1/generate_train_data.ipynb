{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1948: [1.1, 0.3, 0.4, 1.3, 0.9, 1.0, 0.9, 0.3, 0.6, 3.3, 0.9, 0.2, 0.0, 1.5, 1.9, 1.5, 1.3, 1.6], 1952: [], 1956: [0.0, -1.2, -2.8, 0.0, 0.1, -0.5, -0.6, 0.0, -0.9, -1.2, -0.7, 0.0, -1.4, 0.0, -1.0, -2.2, -2.3, -1.1, -2.5], 1960: [-0.3, -0.2, -0.3, -0.2, -0.2, -0.5, -0.3, -0.1, -0.2, -0.5, -0.3, -1.3, -2.3, 0.0, 0.0, 0.0], 1964: [0.6, -2.5, -2.8, -0.7, 0.3, 1.6, -1.8, 0.2, 0.2, -0.5, 1.9, 1.7, 1.0, 1.7, 5.3, -1.3, 1.0], 1968: [2.8, 0.8, 0.0, 0.6, 0.7, 3.8, 0.4, 0.0, 0.0, 1.8, 0.5, 4.2, 2.0, 1.6, 0.0, 0.3], 1972: [-0.7, -2.3, 0.5, 2.3, 0.8, 1.2, -1.9, 2.1, 0.6, -0.3, -2.2, -0.3, 1.8, -2.3, 0.0, 3.4, 0.3, 0.0, 0.2, 0.3], 1976: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.1, 0.1, 0.1, 0.1, 1.1, 0.7, 0.0], 1980: [0.0, 0.1, 0.5, -0.2, 0.9, 0.0, -0.1, -0.1, 0.3, 1.4, 0.2, 0.3, 0.3, 0.5, 0.5, 1.2], 1984: [-0.4, 1.8, 1.8, -0.8, 1.4, 1.9, 0.8, -0.8, -1.7, -1.4, 1.4, -0.7, 0.1, 1.4, 0.8, 0.8, 0.7, -1.5, 0.2], 1988: [0.6, 0.9, 0.7, 0.8, 1.1, 1.4, 1.8, 2.0, 1.0, 1.4, 1.0, 1.4, 0.9, 1.2, 1.7, 0.9, 0.2, 1.4, 0.3, 0.6, -1.2, 1.1], 1992: [-0.1, -0.5, -0.3, -1.0, -2.0, -2.0, -1.6, -2.2, -1.6, -0.3, 0.9, -0.5, -1.7, 0.0, -1.3, -1.2, 0.5], 1996: [-0.9, 1.3, 0.1, 2.2, -0.8, 0.3, -0.3, 2.0, 0.1, -0.2, -1.6, -0.8, -0.3, 0.1, 1.1, -0.2, -1.2, -0.5, -0.6, 0.7], 2000: [-0.6, -0.6, 0.4, -0.5, -0.5, 0.2, 0.3, 1.9, -1.0, -0.7, -1.2, -1.7, 0.3, 0.8, 0.8, 0.2, 0.4, 0.2, -0.3], 2004: [-0.2, -0.4, -0.1, 0.8, 0.1, -1.1, 0.9, -0.2, -1.4, 0.7, 0.0, 0.0, 0.2, -0.1, -0.2, -1.6, 0.2, 0.6], 2008: [-0.2, 0.0, 0.0, 0.2, 0.7, 0.9, -1.4, -0.1, -1.7, -1.3, -0.1, 0.0, -0.2, 0.1, -0.1, -0.1, 0.3, 0.0], 2012: [0.9, 0.9, 1.7, 0.5, -1.4, 0.7, 1.5, 0.4, 0.0, 1.3, 2.0, 0.7, 1.0, 1.7, 1.5], 2016: [-0.2, 0.4, -0.3, -1.2, 0.8, -0.1, -0.5, 0.2, -0.8, -0.4, -1.3, 0.2, 0.2, 0.0, 0.2], 2020: [-0.2, 0.0, 0.9, 0.2, 0.3, 0.1, 0.0, 0.6, -0.4, 0.8, -0.1, -0.2, 0.9, 0.1]}\n",
      "                       Name Nation     R1     R2     R3     R4  Year  \\\n",
      "0          Harrison Dillard    USA   10.4   10.4   10.5   10.5  1948   \n",
      "1              Barney Ewell    USA   10.5   10.5   10.5   10.5  1948   \n",
      "2             Lloyd LaBeach    PAN   10.5   10.5   10.5   10.5  1948   \n",
      "3     Alastair McCorquodale    GBR   10.5   10.5   10.7   10.7  1948   \n",
      "4                Mel Patton    USA   10.6   10.4   10.4   10.4  1948   \n",
      "...                     ...    ...    ...    ...    ...    ...   ...   \n",
      "1422           Hassan Saaid    MDV   10.7   -1.0   -1.0   -1.0  2020   \n",
      "1425           Arturo Rojas    BOL  10.64   -1.0   -1.0   -1.0  2020   \n",
      "1428            Didier Kiki    BEN  10.69   -1.0   -1.0   -1.0  2020   \n",
      "1437         Karalo Maibuca    TUV  11.42   -1.0   -1.0   -1.0  2020   \n",
      "1439          Chijindu Ujah    GBR   -1.0  10.08  10.11  10.11  2020   \n",
      "\n",
      "               Birthday  Height  Weight  heat_r1  heat_r2  heat_r3  \n",
      "0          8 July 1923    178.0    69.0      5.0      1.0      1.0  \n",
      "1     25 February 1918    180.0    71.0      1.0      2.0      1.0  \n",
      "2         28 June 1922    185.0    73.0      3.0      4.0      2.0  \n",
      "3      5 December 1925    183.0    78.0      1.0      3.0      1.0  \n",
      "4     16 November 1924    185.0    72.0      2.0      3.0      2.0  \n",
      "...                 ...     ...     ...      ...      ...      ...  \n",
      "1422      4 March 1992    157.0    60.0      1.0      0.0      0.0  \n",
      "1425       27 May 1993    183.0    67.0      2.0      0.0      0.0  \n",
      "1428  30 November 1995    185.0    84.0      2.0      0.0      0.0  \n",
      "1437      10 June 1999    176.0    64.0      3.0      0.0      0.0  \n",
      "1439      5 March 1994    182.0    81.0      0.0      7.0      3.0  \n",
      "\n",
      "[1274 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "raw_data_path = './dataset/raw_data.csv'\n",
    "wind_list_path = './dataset/wind_list.pkl'\n",
    "\n",
    "### Preprocess the data\n",
    "###     1. process birthday attribute with dropping the place of the birth in the string\n",
    "###     2. process record of the performance with replacing '-' into '-1 (h0)'\n",
    "###     3. extract weight and height attribute from body and drop the rows with no body information\n",
    "###     4. drop some unuseful columns\n",
    "\n",
    "raw_data = pd.read_csv(raw_data_path)\n",
    "raw_data.dropna(subset=['Birth', 'Body', 'Year'], inplace=True)\n",
    "raw_data['Birthday'] = raw_data['Birth'].apply(lambda x: x.split(\"in\")[0])\n",
    "raw_data.loc[raw_data['R1'] == '–', 'R1'] = '-1 (h0)'\n",
    "raw_data.loc[raw_data['R2'] == '–', 'R2'] = '-1 (h0)'\n",
    "raw_data.loc[raw_data['R3'] == '–', 'R3'] = '-1 (h0)'\n",
    "drop_index = []\n",
    "for idx in raw_data.index:\n",
    "    try:\n",
    "        raw_data.loc[idx, 'Height'] = int(raw_data['Body'][idx].split()[0])\n",
    "        raw_data.loc[idx, 'Weight'] = int(raw_data['Body'][idx].split()[3])\n",
    "    except:\n",
    "        drop_index.append(idx)\n",
    "raw_data.drop(index=drop_index, inplace=True)\n",
    "raw_data.drop(columns=['Gold', 'Silver', 'Bronze', 'Birth', 'Body'], inplace=True)\n",
    "\n",
    "### Process the information of wind\n",
    "\n",
    "wind_list = pd.read_pickle(wind_list_path)\n",
    "wind_dict = {}\n",
    "for idx in range(len(wind_list)):\n",
    "    wind_dict[1948 + idx * 4] = wind_list[idx]\n",
    "print(wind_dict)\n",
    "\n",
    "### Process the data of performance record\n",
    "###     1. to make sure the data could be convert to float type\n",
    "###     2. extract the heat information\n",
    "\n",
    "raw_data['R1'] = raw_data['R1'].apply(lambda x: re.sub(r'[\\[\\]w]', '', x))\n",
    "raw_data['R2'] = raw_data['R2'].apply(lambda x: re.sub(r'[\\[\\]w]', '', x))\n",
    "raw_data['R3'] = raw_data['R3'].apply(lambda x: re.sub(r'[\\[\\]w]', '', x))\n",
    "\n",
    "raw_data['R1'] = raw_data['R1'].apply(lambda x: re.sub('–', '-1', x))\n",
    "raw_data['R2'] = raw_data['R2'].apply(lambda x: re.sub('–', '-1', x))\n",
    "raw_data['R3'] = raw_data['R3'].apply(lambda x: re.sub('–', '-1', x))\n",
    "raw_data['R4'] = raw_data['R3'].apply(lambda x: re.sub('–', '-1', x))\n",
    "for i in raw_data.index:\n",
    "    p1 = raw_data['R1'][i].find('h')\n",
    "    p2 = raw_data['R2'][i].find('h')\n",
    "    p3 = raw_data['R3'][i].find('h')\n",
    "    raw_data.loc[i, 'heat_r1'] = int(raw_data['R1'][i][p1+1:-1])\n",
    "    raw_data.loc[i, 'heat_r2'] = int(raw_data['R2'][i][p2+1:-1])\n",
    "    raw_data.loc[i, 'heat_r3'] = int(raw_data['R3'][i][p3+1:-1])\n",
    "    p1 = raw_data['R1'][i].find('(')\n",
    "    p2 = raw_data['R2'][i].find('(')\n",
    "    p3 = raw_data['R3'][i].find('(')\n",
    "    p4 = raw_data['R4'][i].find('(')\n",
    "    raw_data.loc[i, 'R1'] = float(raw_data['R1'][i][:p1])\n",
    "    raw_data.loc[i, 'R2'] = float(raw_data['R2'][i][:p2])\n",
    "    raw_data.loc[i, 'R3'] = float(raw_data['R3'][i][:p3])\n",
    "    raw_data.loc[i, 'R4'] = float(raw_data['R4'][i][:p3])\n",
    "\n",
    "\n",
    "num_heat = [raw_data.groupby('Year')['heat_r1'].max(), # use to match the wind information\n",
    "            raw_data.groupby('Year')['heat_r2'].max(), \n",
    "            raw_data.groupby('Year')['heat_r3'].max()]\n",
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract train data from raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Name  NOC  Weight  Height           Birthday  Year  Round  \\\n",
      "0     Harrison Dillard  USA    69.0   178.0       8 July 1923   1948      1   \n",
      "1     Harrison Dillard  USA    69.0   178.0       8 July 1923   1948      2   \n",
      "2     Harrison Dillard  USA    69.0   178.0       8 July 1923   1948      3   \n",
      "3     Harrison Dillard  USA    69.0   178.0       8 July 1923   1948      4   \n",
      "4         Barney Ewell  USA    71.0   180.0  25 February 1918   1948      1   \n",
      "...                ...  ...     ...     ...                ...   ...    ...   \n",
      "2291       Didier Kiki  BEN    84.0   185.0  30 November 1995   2020      1   \n",
      "2292    Karalo Maibuca  TUV    64.0   176.0      10 June 1999   2020      1   \n",
      "2293     Chijindu Ujah  GBR    81.0   182.0      5 March 1994   2020      2   \n",
      "2294     Chijindu Ujah  GBR    81.0   182.0      5 March 1994   2020      3   \n",
      "2295     Chijindu Ujah  GBR    81.0   182.0      5 March 1994   2020      4   \n",
      "\n",
      "      Wind  Label  \n",
      "0      0.9  10.40  \n",
      "1      0.0  10.40  \n",
      "2      0.9  10.50  \n",
      "3      1.6  10.50  \n",
      "4      1.1  10.50  \n",
      "...    ...    ...  \n",
      "2291   0.0  10.69  \n",
      "2292   0.9  11.42  \n",
      "2293   0.8  10.08  \n",
      "2294   0.8  10.11  \n",
      "2295   0.1  10.11  \n",
      "\n",
      "[2255 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.DataFrame(columns=['Name', 'NOC', 'Weight', 'Height', 'Birthday' , 'Year', 'Round', 'Wind', 'Label'])\n",
    "for _, row in raw_data.iterrows():\n",
    "    for round in range(1, 5):\n",
    "        col = f'R{round}'\n",
    "        if row[col] == -1:\n",
    "            continue\n",
    "        try:\n",
    "            wind_idx = 0 if round == 1 else num_heat[round - 2][row['Year']]\n",
    "            wind_idx = wind_idx + row[f'heat_r{round}'] - 1 if round != 4 else -1\n",
    "            wind = wind_dict[row['Year']][int(wind_idx)]\n",
    "        except:\n",
    "            break\n",
    "        new_row = list(row[['Name', 'Nation', 'Weight', 'Height', 'Birthday' , 'Year']])\n",
    "        new_row += [round, wind, row[col]]\n",
    "        train_data.loc[len(train_data)] = new_row\n",
    "train_data.dropna(inplace=True)\n",
    "train_data = train_data.loc[train_data['Label'] <= 11.5]\n",
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process the train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'USA': 0, 'GBR': 1, 'JAM': 2, 'FRA': 3, 'CAN': 4, 'NGR': 5, 'TTO': 6, 'BRA': 7, 'URS': 8, 'JPN': 9, 'GHA': 10, 'POL': 11, 'CUB': 12, 'AUS': 13, 'BAH': 14, 'GDR': 15, 'ITA': 16, 'GER': 17, 'CIV': 18, 'CHN': 19, 'FRG': 20, 'SKN': 21, 'BAR': 22, 'HUN': 23, 'SEN': 24, 'INA': 25, 'VEN': 26, 'ESP': 27, 'RSA': 28, 'KEN': 29, 'QAT': 30, 'GRE': 31, 'ANT': 32, 'CMR': 33, 'POR': 34, 'BEL': 35, 'NAM': 36, 'PAK': 37, 'BUL': 38, 'DOM': 39, 'PAN': 40, 'SUR': 41, 'GAM': 42, 'CGO': 43, 'UGA': 44, 'CYP': 45, 'TPE': 46, 'THA': 47, 'ISV': 48, 'SGP': 49, 'AHO': 50, 'IRI': 51, 'PUR': 52, 'MAD': 53, 'SUI': 54, 'MDV': 55, 'UKR': 56, 'NZL': 57, 'CHI': 58, 'MAS': 59, 'BER': 60, 'NOR': 61, 'ZAM': 62, 'BUR': 63, 'LBR': 64, 'SLE': 65, 'KSA': 66, 'NED': 67, 'KOR': 68, 'OMA': 69, 'TCH': 70, 'GAB': 71, 'MLI': 72, 'BAN': 73, 'TGA': 74, 'RUS': 75, 'GUY': 76, 'EUN': 77, 'FIJ': 78, 'CAY': 79, 'MEX': 80, 'ISL': 81, 'GUI': 82, 'BEN': 83, 'MRI': 84, 'ARG': 85, 'AUT': 86, 'SWE': 87, 'TUR': 88, 'LES': 89, 'PHI': 90, 'BOL': 91, 'BRN': 92, 'URU': 93, 'COL': 94, 'KAZ': 95, 'GBS': 96, 'HKG': 97, 'HAI': 98, 'PLW': 99, 'FIN': 100, 'TAN': 101, 'AZE': 102, 'MLT': 103, 'ESA': 104, 'FSM': 105, 'ZIM': 106, 'SEY': 107, 'SLO': 108, 'KUW': 109, 'MTN': 110, 'PNG': 111, 'ANG': 112, 'ASA': 113, 'VAN': 114, 'LAO': 115, 'CAF': 116, 'SRI': 117, 'COK': 118, 'SOL': 119, 'COM': 120, 'IVB': 121, 'SMR': 122, 'TOG': 123, 'ISR': 124, 'IND': 125, 'SWZ': 126, 'ROU': 127, 'SUD': 128, 'VIE': 129, 'WIF': 130, 'STP': 131, 'AFG': 132, 'HON': 133, 'BOT': 134, 'GEQ': 135, 'GUA': 136, 'PER': 137, 'IRL': 138, 'IRQ': 139, 'LBN': 140, 'ETH': 141, 'BRU': 142, 'LIE': 143, 'BIZ': 144, 'MKD': 145, 'NCA': 146, 'MON': 147, 'MAW': 148, 'CAM': 149, 'ARU': 150, 'CRC': 151, 'CRO': 152, 'CZE': 153, 'UZB': 154, 'VIN': 155, 'TUV': 156, 'ECU': 157, 'ALG': 158, 'EGY': 159, 'ALB': 160, 'EST': 161, 'PLE': 162, 'GEO': 163, 'LUX': 164, 'PAR': 165, 'NEP': 166, 'MOZ': 167, 'MGL': 168, 'MAR': 169, 'MAL': 170, 'LTU': 171, 'GRN': 172, 'LCA': 173, 'LAT': 174, 'KIR': 175, 'JOR': 176, 'SVK': 177, 'GUM': 178, 'KGZ': 179}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>Nation</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Year</th>\n",
       "      <th>Round</th>\n",
       "      <th>Wind</th>\n",
       "      <th>isHometown</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harrison Dillard</td>\n",
       "      <td>25.062286</td>\n",
       "      <td>0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>21.777553</td>\n",
       "      <td>1948</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harrison Dillard</td>\n",
       "      <td>25.062286</td>\n",
       "      <td>0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>21.777553</td>\n",
       "      <td>1948</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harrison Dillard</td>\n",
       "      <td>25.062286</td>\n",
       "      <td>0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>21.777553</td>\n",
       "      <td>1948</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harrison Dillard</td>\n",
       "      <td>25.062286</td>\n",
       "      <td>0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>21.777553</td>\n",
       "      <td>1948</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Barney Ewell</td>\n",
       "      <td>30.425736</td>\n",
       "      <td>0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>21.913580</td>\n",
       "      <td>1948</td>\n",
       "      <td>1</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2291</th>\n",
       "      <td>Didier Kiki</td>\n",
       "      <td>25.667351</td>\n",
       "      <td>83</td>\n",
       "      <td>84.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>24.543462</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2292</th>\n",
       "      <td>Karalo Maibuca</td>\n",
       "      <td>22.140999</td>\n",
       "      <td>156</td>\n",
       "      <td>64.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>20.661157</td>\n",
       "      <td>2020</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2293</th>\n",
       "      <td>Chijindu Ujah</td>\n",
       "      <td>27.405886</td>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>24.453568</td>\n",
       "      <td>2020</td>\n",
       "      <td>2</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294</th>\n",
       "      <td>Chijindu Ujah</td>\n",
       "      <td>27.405886</td>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>24.453568</td>\n",
       "      <td>2020</td>\n",
       "      <td>3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2295</th>\n",
       "      <td>Chijindu Ujah</td>\n",
       "      <td>27.405886</td>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>182.0</td>\n",
       "      <td>24.453568</td>\n",
       "      <td>2020</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2238 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Name        Age  Nation  Weight  Height        BMI  Year  \\\n",
       "0     Harrison Dillard  25.062286       0    69.0   178.0  21.777553  1948   \n",
       "1     Harrison Dillard  25.062286       0    69.0   178.0  21.777553  1948   \n",
       "2     Harrison Dillard  25.062286       0    69.0   178.0  21.777553  1948   \n",
       "3     Harrison Dillard  25.062286       0    69.0   178.0  21.777553  1948   \n",
       "4         Barney Ewell  30.425736       0    71.0   180.0  21.913580  1948   \n",
       "...                ...        ...     ...     ...     ...        ...   ...   \n",
       "2291       Didier Kiki  25.667351      83    84.0   185.0  24.543462  2020   \n",
       "2292    Karalo Maibuca  22.140999     156    64.0   176.0  20.661157  2020   \n",
       "2293     Chijindu Ujah  27.405886       1    81.0   182.0  24.453568  2020   \n",
       "2294     Chijindu Ujah  27.405886       1    81.0   182.0  24.453568  2020   \n",
       "2295     Chijindu Ujah  27.405886       1    81.0   182.0  24.453568  2020   \n",
       "\n",
       "      Round  Wind  isHometown  Label  \n",
       "0         1   0.9         0.0  10.40  \n",
       "1         2   0.0         0.0  10.40  \n",
       "2         3   0.9         0.0  10.50  \n",
       "3         4   1.6         0.0  10.50  \n",
       "4         1   1.1         0.0  10.50  \n",
       "...     ...   ...         ...    ...  \n",
       "2291      1   0.0         0.0  10.69  \n",
       "2292      1   0.9         0.0  11.42  \n",
       "2293      2   0.8         0.0  10.08  \n",
       "2294      3   0.8         0.0  10.11  \n",
       "2295      4   0.1         0.0  10.11  \n",
       "\n",
       "[2238 rows x 11 columns]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import calendar\n",
    "olympic_list = {\n",
    "    1948: ['GBR', '19480730'],\n",
    "    1952: ['FIN', '19520721'],\n",
    "    1956: ['AUS', '19561123'],\n",
    "    1960: ['ITA', '19600831'],\n",
    "    1964: ['JPN', '19641014'],\n",
    "    1968: ['MEX', '19681013'], \n",
    "    1972: ['GER', '19720831'],\n",
    "    1976: ['CAN', '19760723'],\n",
    "    1980: ['URS', '19800724'],\n",
    "    1984: ['USA', '19840803'],\n",
    "    1988: ['KOR', '19880923'],\n",
    "    1992: ['ESP', '19920731'],\n",
    "    1996: ['USA', '19960726'],\n",
    "    2000: ['AUS', '20000922'],\n",
    "    2004: ['GRE', '20040821'],\n",
    "    2008: ['CHN', '20080815'],\n",
    "    2012: ['GBR', '20120804'],\n",
    "    2016: ['BRA', '20160813'],\n",
    "    2020: ['JPN', '20210731'],\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "drop_index = []\n",
    "for idx, row in train_data.iterrows():\n",
    "    birthday = row['Birthday']\n",
    "    try:\n",
    "        month = birthday.split()[1]\n",
    "    except:\n",
    "        drop_index.append(idx)\n",
    "        continue\n",
    "    birthday = birthday.replace(month, str(list(calendar.month_name).index(month)))\n",
    "    while birthday[-1] == ' ':\n",
    "        birthday = birthday[:-1]\n",
    "    birthday = datetime.strptime(birthday, \"%d %m %Y\")\n",
    "    train_data.loc[idx, \"Age\"] = (datetime.strptime(olympic_list[row['Year']][1], \"%Y%m%d\") - birthday).days / 365.25\n",
    "    train_data.loc[idx, \"isHometown\"] = int(row['NOC'] == olympic_list[row['Year']][0])\n",
    "    train_data.loc[idx, \"BMI\"] = row['Weight'] * 10000 / row['Height'] / row['Height']\n",
    "train_data.drop(index=drop_index, inplace=True)\n",
    "train_data.dropna(inplace=True)\n",
    "nation_cnt = dict(train_data.groupby(by=['NOC']).count()['Label'].sort_values(ascending=False))\n",
    "nation_list = {}\n",
    "nation_index = 0\n",
    "for k, i in nation_cnt.items():\n",
    "    nation_list[k] = nation_index\n",
    "    nation_index += 1\n",
    "print(nation_list)\n",
    "train_data['Nation'] = train_data['NOC'].apply(lambda x: nation_list[x])\n",
    "\n",
    "train_data_path = './dataset/train_data.csv'\n",
    "cols = ['Name', 'Age', 'Nation', 'Weight', 'Height', 'BMI', 'Year', 'Round', 'Wind', 'isHometown', 'Label']\n",
    "train_data = train_data[cols]\n",
    "train_data.to_csv(train_data_path, index=False)\n",
    "train_data\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-final",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
